services:
  # PostgreSQL with pgvector extension and performance optimization
  postgres:
    image: ankane/pgvector:latest
    container_name: claude-context-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: claude_context
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-code-context-secure-password}
      # Enable pgvector extension
      POSTGRES_INITDB_ARGS: "-E UTF8"
    ports:
      - "5533:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d
      - ./database/postgresql-simple.conf:/etc/postgresql/postgresql.conf
    command: >
      postgres
      -c config_file=/etc/postgresql/postgresql.conf
      -c max_connections=200
      -c shared_buffers=256MB
      -c effective_cache_size=1GB
      -c work_mem=16MB
      -c maintenance_work_mem=128MB
      -c checkpoint_timeout=15min
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c autovacuum_naptime=10s
      -c autovacuum_vacuum_scale_factor=0.05
      -c autovacuum_analyze_scale_factor=0.02
      -c max_parallel_workers_per_gather=4
      -c max_parallel_workers=8
      -c statement_timeout=300000
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -p 5432"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - claude-context-network
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  # Qdrant vector database (required for crawl4ai)
  qdrant:
    image: qdrant/qdrant:latest
    container_name: claude-context-qdrant
    restart: unless-stopped
    ports:
      - "6333:6333" # REST/gRPC (port verified free via `ss -ltn`)
    volumes:
      - qdrant_storage:/qdrant/storage
    healthcheck:
      test: ["CMD-SHELL", "timeout 1 bash -c 'cat < /dev/null > /dev/tcp/localhost/6333' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - claude-context-network

  # Neo4j graph database (for Cognee knowledge graphs)
  neo4j:
    image: neo4j:5.15.0
    container_name: claude-context-neo4j
    restart: unless-stopped
    ports:
      - "7474:7474" # HTTP
      - "7687:7687" # Bolt
    environment:
      NEO4J_AUTH: neo4j/secure-graph-password
      NEO4J_PLUGINS: '["apoc", "graph-data-science"]'
      NEO4J_dbms_security_procedures_unrestricted: apoc.*,gds.*
      NEO4J_dbms_security_procedures_allowlist: apoc.*,gds.*
      # Performance tuning
      NEO4J_dbms_memory_heap_initial__size: 512M
      NEO4J_dbms_memory_heap_max__size: 2G
      NEO4J_dbms_memory_pagecache_size: 1G
      NEO4J_dbms_connector_bolt_thread__pool__min__size: 5
      NEO4J_dbms_connector_bolt_thread__pool__max__size: 400
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
      - neo4j_import:/var/lib/neo4j/import
      - neo4j_plugins:/plugins
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:7474 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - claude-context-network
    deploy:
      resources:
        limits:
          memory: 3G
        reservations:
          memory: 1G

  # Crawl4AI service with chunking, code detection, and AI summaries
  crawl4ai:
    build:
      context: ..
      dockerfile: services/crawl4ai-runner/Dockerfile
    container_name: claude-context-crawl4ai
    restart: unless-stopped
    ports:
      - "7070:7070"
    env_file:
      - ../.env.crawl4ai
    environment:
      PLAYWRIGHT_BROWSERS_PATH: /ms-playwright
    shm_size: '2gb'  # Required for Chromium browser
    volumes:
      - playwright_cache:/ms-playwright
      - ../services/crawl4ai-runner:/app  # Mount source for development
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7070/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s  # Give time for Playwright to install
    extra_hosts:
      - "host.docker.internal:host-gateway"  # Map host.docker.internal to host machine (Linux)
    networks:
      - claude-context-network
    depends_on:
      postgres:
        condition: service_healthy
      qdrant:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G

  # SPLADE sparse vector service for hybrid search
  splade-runner:
    build:
      context: ./splade-runner
    container_name: claude-context-splade
    restart: unless-stopped
    ports:
      - "30004:8000"
    environment:
      # Using distilled model - 2x smaller, 91% quality, ~500MB VRAM instead of 2GB+
      MODEL_NAME: ${SPLADE_MODEL_NAME:-rasyosef/splade-small}
      # Internal batch size to prevent OOM - processes large batches in smaller chunks
      SPLADE_INTERNAL_BATCH_SIZE: ${SPLADE_INTERNAL_BATCH_SIZE:-8}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 300s  # Give time for model download
    networks:
      - claude-context-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
          memory: 4G
        limits:
          memory: 6G

  # Cognee AI memory framework (custom build with Qdrant adapter)
  cognee:
    build:
      context: ./cognee
      dockerfile: Dockerfile
    container_name: cognee
    restart: unless-stopped
    ports:
      - "8340:8000"
    env_file:
      - ./cognee/.env
    stdin_open: true
    tty: true
    extra_hosts:
      - "host.docker.internal:host-gateway"  # Access host services (GTE embeddings)
    networks:
      - claude-context-network
    depends_on:
      postgres:
        condition: service_healthy
      qdrant:
        condition: service_healthy
      neo4j:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  # Real-time API middleware with WebSocket monitoring
  api-server:
    build:
      context: ..
      dockerfile: services/api-server/Dockerfile
    container_name: claude-context-api-server
    restart: unless-stopped
    ports:
      - "3030:3030"
    env_file:
      - ../.env
    environment:
      POSTGRES_URL: postgres://postgres:${POSTGRES_PASSWORD:-code-context-secure-password}@postgres:5432/claude_context
      QDRANT_URL: http://qdrant:6333
      CRAWL4AI_URL: http://crawl4ai:7070
      PORT: 3030
      NODE_ENV: production
      NODE_OPTIONS: "--max-old-space-size=3072"  # Use 3GB for Node.js heap
      CORE_MODULE_PATH: /dist/index.js
      # Embedding services (running on host machine)
      STELLA_PORT: 30001
      CODERANK_PORT: 30002
      STELLA_HOST: host.docker.internal
      CODERANK_HOST: host.docker.internal
      EMBEDDING_BATCH_SIZE_PER_REQUEST: 22
      # Reranking service (running on host machine)
      ENABLE_RERANKING: ${ENABLE_RERANKING:-true}
      RERANKER_URL: http://host.docker.internal:30003
      RERANK_INITIAL_K: ${RERANK_INITIAL_K:-150}
      RERANK_FINAL_K: ${RERANK_FINAL_K:-20}
      # Hybrid search with SPLADE
      ENABLE_HYBRID_SEARCH: ${ENABLE_HYBRID_SEARCH:-true}
      SPLADE_URL: http://splade-runner:8000
      HYBRID_DENSE_WEIGHT: ${HYBRID_DENSE_WEIGHT:-0.6}
      HYBRID_SPARSE_WEIGHT: ${HYBRID_SPARSE_WEIGHT:-0.4}
      # Concurrent batch processing - balanced for performance
      CHUNK_BATCH_SIZE: ${CHUNK_BATCH_SIZE:-22}
      MAX_CONCURRENT_BATCHES: ${MAX_CONCURRENT_BATCHES:-1}
      # Enhanced AST symbol extraction
      ENABLE_SYMBOL_EXTRACTION: ${ENABLE_SYMBOL_EXTRACTION:-true}
      # Large language model configuration for smart retrieval
      # LLM_API_KEY loaded from env_file (../.env)
      # LLM_API_BASE loaded from env_file (../.env)
      # MODEL_NAME loaded from env_file (../.env)
    volumes:
      - /home/mewtwo:/home/mewtwo:ro  # Mount home directory read-only for local indexing
    extra_hosts:
      - "host.docker.internal:host-gateway"  # Map host.docker.internal to host machine (Linux)
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3030/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - claude-context-network
    depends_on:
      postgres:
        condition: service_healthy
      qdrant:
        condition: service_healthy
      crawl4ai:
        condition: service_healthy
      splade-runner:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G

volumes:
  postgres_data:
    driver: local
  qdrant_storage:
    driver: local
  playwright_cache:
    driver: local
  neo4j_data:
    driver: local
  neo4j_logs:
    driver: local
  neo4j_import:
    driver: local
  neo4j_plugins:
    driver: local

networks:
  claude-context-network:
    driver: bridge
